{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering vs Content-based filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collaborative filtering  \n",
    "Recomments items based on ratings of users who gave similar ratings as you (requires ratings)\n",
    "- Content-based filtering:  \n",
    "Recommends items to you based on features of user and item to find a good match (requires feature vector of a user)\n",
    "\n",
    "Example of user features $x_{u}^{(i)}$ for user $j$\n",
    "- Age\n",
    "- Gender ($1$ hot encoding)\n",
    "- Country ($1$ hot for $200$ countries)\n",
    "- Movies watched (movies wathced, e.g., $1000$)\n",
    "- Average rating per genre \n",
    "\n",
    "Example of movie features $x_{m}^{(i)}$ for user $i$\n",
    "- Year\n",
    "- Genre/Genres \n",
    "- Reviews (several features...)\n",
    "- Average rating (per user/demographic...)\n",
    "\n",
    "> Alborithm matches these two vectors\n",
    "\n",
    "#### Consider two vectors:  \n",
    "$v_{u}^{(j)}$ vector computed from $x_{u}^{(j)}$  \n",
    "$v_{m}^{(i)}$ vector computed from $x_{m}^{(i)}$  \n",
    "that represent $w^{(j)}\\cdot c^{(i)} + b^{(j)}$ with $b^{(j)}=0$ (shown not to affect results) as $v_{u}^{(j)}\\cdot v_{m}^{(i)}$, that says _how much a given user $j$ likes the movie $i$_. \n",
    "\n",
    "#### Computing the feature \\& user vectors \n",
    "\n",
    "> Deep learning approach $x_{m}\\rightarrow v_{m}$ with different networks for user and movie\n",
    "\n",
    "Consider _user network_: $x_{u}\\rightarrow 128 \\rightarrow 64 \\rightarrow 32 \\rightarrow v_{u}$\n",
    "\n",
    "Consider _movie network_: $x_{u}\\rightarrow 256 \\rightarrow 128 \\rightarrow 32 \\rightarrow v_{u}$\n",
    "\n",
    "**Note** if $v_{u}$ and $v_m$ are binary, than we can consider sigmoid function and instead $v_{u}^{(j)}\\cdot v_{m}^{(i)}$ calculate $g(v_{u}^{(j)}\\cdot v_{m}^{(i)})$ to predict probability that $y^{(i,j)}=1$. \n",
    "\n",
    "Training the network with **cost function** as $J$ using a $\\color{red}{\\text{singular}}$ cost function for users and movies: \n",
    "\n",
    "$$\n",
    "J(x^{(1)},...,x^{(n_m)}) = \\frac{1}{2}\\sum_{(i,j):r(i,j) = 1}(v_{u}^{(j)}\\cdot v_{m}^{(i)} + 0 - y^{(i,j)})^2 + \\text{(NN regularization term)}\n",
    "$$\n",
    "\n",
    "and train it with gradient descent. \n",
    "\n",
    "This network can also be used to find similar items.\n",
    "\n",
    "After training we obtain \n",
    "- $v_{u}^{(j)}$, a vector of length $32$ that encodes user $j$ with features $x_{u}^{(j)}$\n",
    "- $v_{m}^{(i)}$, a vector of length $32$ that encodes movie $i$ with features $x_{m}^{(i)}$\n",
    "\n",
    "To find **simular movies** consider distance between vectors $||v_{m}^{(k)}-v_{m}^{(i)}||^2$ and find for what $k$ it is small.  \n",
    "**Note** This can be pre-computed! So a new user, once he selecta a movie, get _recommendations_ for other, similar movies.  \n",
    "\n",
    "> For this algorithm to work well, features must be carefully engeneered\n",
    "\n",
    "**Limitaitons**: computationally expensive when number of movies is very large.\n",
    "\n",
    "### Recomendations from large catalogue\n",
    "\n",
    "In order to avoid recomputing the entire network for every new user, which is __computationally very expensive__ for large number of items consider: \n",
    "> Retrieval & Ranking\n",
    "\n",
    "**Retrieval step** (ensure broad coverage)  \n",
    "- Generate large list of plausable item candidates: \n",
    "1. for each of the last 10 movies watched by the user find 10 most similar movies vis $||v_{m}^{(k)}-v_{m}^{(i)}||^2$ which can be pre-computed. End executed via __look-up table__. \n",
    "2. for most viewed 3 generes, find the top 10 movies \n",
    "3. Top 20 movies in the country... \n",
    "\n",
    "- Combine retrieved items into list, removing duplicates and items already watched / purchased\n",
    "\n",
    "**Note**: Retrieving more items leads to __better performace__ but __slower speed__.  \n",
    "To analyze the trade-off; consider __offline__ experiments to find whether retrieving additional items leads to more relevant recomendations ($p^{(i,j)}=1$ of items desplayed to the user are higher). \n",
    "\n",
    "**Ranking step** (get the best option)\n",
    "- Take the list of the learned movies and rank them using the learned model (feed $x_u$ and $x_m$ to the neural network). **Note** $x_m\\rightarrow v_m$ can be pre-cpmputed in advance, and only $x_u\\rightarrow v_u$ would need to be computed \n",
    "- Display ranked items to the user\n",
    "\n",
    "### Tesorflow implementaitons\n",
    "\n",
    "Implement two networks with dense layers.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
