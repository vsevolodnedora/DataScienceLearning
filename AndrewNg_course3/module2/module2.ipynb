{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making recommendations\n",
    "\n",
    "### Predicting movie ratings \n",
    "\n",
    "Given a list of movies, $N$ users rated movies from 1-5. Set $r(i,j)=1$ if a user $i$ rated movie $j$. Then, $y^{i,j}\\in\\{0,1\\}$ is the rating given by the user $j$ to the movie $i$. \n",
    "\n",
    "## Collaborative filtrering\n",
    "\n",
    "Consider a table where columns besides last two are number of stars given  \n",
    "Last two columns indicate the movie content, action or romanse   \n",
    "Some users did not give stars/watch some movies.  \n",
    "We need to predict which movie to recommend to what user  \n",
    "|        | User1 | User2 | ... | User N | $x_1$ (romance) | $x_2$ (action)\n",
    "| ------ | ----- |----- |----- |----- |----- | ----- |\n",
    "| Movie 1 |  5 | ? | ? | 0 | 1.0 | 0.01  \n",
    "| Movie 2 |\n",
    "| ... |\n",
    "| Movie 3 |\n",
    "\n",
    "Assume that predicted rating is $w\\cdot x^{i} + b$ as a linear regression \n",
    "For $j$ user and movie $i$ the formula is \n",
    "$$\n",
    "w^{(j)}\\cdot x^{(i)} + b^{(j)}\n",
    "$$\n",
    "$w^{(i)},b^{(i)}$ are parameters for user $j$  \n",
    "$x^{(i)}$ is the feature vector for movie $i$  \n",
    "and $m_j$ is the number of movies rated by user $j$.  \n",
    "Goal: learn $w^{(j)}$ and $b^{(j)}$\n",
    "\n",
    "$$\n",
    "J(w^{(j)},b^{(j)}) = \\frac{1}{2m^{(j)}} \\sum_{i:r(i,j) = 1}(w^{(j)}\\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \\frac{\\lambda}{2m^{(j)}}\\sum_{k=1}^{n}\\Big( w_{k}^{(j)} \\Big)^2\n",
    "$$\n",
    "where the summation is done over the movies that user $j$ actually rated, $i:r(i,j)=1$  \n",
    "Similar to the cost function of the linear regression plus regularization to prevent overfitting.  \n",
    "$\\min J(w^{(j)},b^{(j)})$ gives the values for the parameters.  \n",
    "\n",
    "For all users we need to sum over all users as \n",
    "\n",
    "$$\n",
    "J = \\frac{1}{2} \\sum_{j=1}^{n_u} \\sum_{i:r(i,j) = 1}(w^{(j)}\\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \\frac{\\lambda}{2}\\sum_{j=1}^{n_u}\\sum_{k=1}^{n}\\Big( w_{k}^{(j)} \\Big)^2\n",
    "$$\n",
    "\n",
    "Note, we got rid of the $1/m^{(j)}$. For.. simplicity?..  \n",
    "\n",
    "Now, use optimization algorithm to find the values.  \n",
    "\n",
    "\n",
    "#### Find fratures $x_i$ if they are not available\n",
    "\n",
    "Assume that we already have $w^{(j)}$ and $b^{(j)}$, then as we know the values for all users, labels $\\mathbf{y}^{(i)}$, we can compute $\\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(j)} + \\mathbf{b}^{(j)} = \\mathbf{y}^{(j)}$. I.e., we have linear system of equations that we can solve for $\\mathbf{x}^{(j)}$ (and assume that $\\mathbf{b}^{(j)}=0$). So we get a system of linear equations. Solving it requires inverting a $N\\times M$ matrix. Solving it requires many users. \n",
    "\n",
    "Cost function: \n",
    "\n",
    "$$\n",
    "J = \\frac{1}{2} \\sum_{j=1}^{n_u} \\sum_{i:r(i,j) = 1}(w^{(j)}\\cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \\frac{\\lambda}{2}\\sum_{j=1}^{n_u}\\sum_{k=1}^{n}\\Big( w_{k}^{(j)} \\Big)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
