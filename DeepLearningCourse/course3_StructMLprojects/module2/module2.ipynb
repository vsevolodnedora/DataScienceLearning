{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrying out Error Analysis\n",
    "\n",
    "Consider a classified that makes errors on a particular data. \n",
    "- Collect $N$ mislabelled dev set examples  \n",
    "- Cound how many are of that partuclar class that seem to be the problem\n",
    "- If it is $X\\%$ are mislabeled, than it means that if you **do** solve the problem, it will only improve the model by this $X\\%$.  The relative decrease might be quite small and might not be worth it. \n",
    "\n",
    "Cieling of the problem: how well can we actially make model. \n",
    "\n",
    "Thus, if in this $N$ there is a large paercentage error is due to a given class, so that imporving this error will lead to a noticable overall model imporvement, than it is worth it. \n",
    "\n",
    "This is **Error Analysis**.  \n",
    "\n",
    "Evaluate multiple ideas in parallel. Explore multiple ideas with a table and spreadshits. There one can put percentages of mislabeled examples for each category. Final row would be the % of the total sample to identify which problem is the most prominent and solving what problem with help impoving the model overall. \n",
    "\n",
    "### Incorrectly labelled data\n",
    "\n",
    "This is e.g., miscalssified or mislabelled examples. Deep-learning algorithms are quite robust if errors ar **reasonably random** if the actual percentage of errors is not large.  \n",
    "\n",
    "If the error is **sytematic** than classifiier will learn the error.  \n",
    "\n",
    "In error analysis an _incorrectly labeled_ can be added as an additional column to help identify what is the percetange of error is due to incorrectly labeled data.  \n",
    "\n",
    "Usually, it does not make a significant difference to correct for mislabeled examples. \n",
    "\n",
    "> Error analysis can help to chose a classifier \n",
    "\n",
    "Manual fixing mislables. \n",
    "- Adviced to be applied to both dev and test sets equally to assure that the distribution does not differ betweeen the two\n",
    "- Look at both '1' and '0' mislabels. \n",
    "- It is less important to correct labels in the train set. It is also possible that the trand data **can** be from different distribution\n",
    "\n",
    "### Move fast and break things\n",
    "\n",
    "Build you system fast and then try to impove it using Bias/Variance analysis and Error aanlyssi to prioritize the next step. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing on Different Distributions\n",
    "\n",
    "It is now common to have a train dataset from a different distribution compared to dev/test sets\n",
    "\n",
    "Consider a situation where there is large train set from distribution 1 and a small set of data from distribution 2 on which the model will actually be evaluated.  \n",
    "\n",
    "The best option is to train the model on distribution 1 + $50\\%$ of the distribution 2 and the dev/test sets are from distribution 2 ONLY. \n",
    "\n",
    "Consider another situation. Building a speach recognition for a specific tool. Assume that there is a plethora of data from other speech recognition projects. There is also a much smaller dataset from speach activated uses directly related to this tool. It has **different** distribution. \n",
    "\n",
    "Set train set using the general data + a fraction of the specific set and use the rest from the specific test for dev/test sets. \n",
    "\n",
    "### Bias and Variance with Mismathced Data Distributions\n",
    "\n",
    "> The way bias and variance is analyzed changes when distributions of train and test/dev tests are different\n",
    "\n",
    "If train error now $\\ll$ than dev error this is no longer a sign of a large bias! The different distribution might affect the result. \n",
    "\n",
    "Define a new set, `train-dev` set that has the same distribution as train set but **is not** used for training.  \n",
    "Having the same distribution it allows to estimate the error introduced by the model due to useen data or due to new distribution. \n",
    "\n",
    "#### Problems:\n",
    "\n",
    "Than if train error $\\ll$ 'train-dev' error; $\\rightarrow$ **high variance problem**\n",
    "The model does not generlize well on the same distribution data.  \n",
    "\n",
    "if train error $\\sim$ 'train-dev' error; but train error $\\ll$ dev set error' $\\rightarrow$ **data mismatch problem**\n",
    "\n",
    "If bayes error (proxied by humman leve) is $\\ll$ than train error $\\rightarrow$ **high bias problem**\n",
    "\n",
    "If both bayes error (proxied by humman leve) is $\\ll$ than train error **AND** but train error $\\ll$ dev set error' $\\rightarrow$ **data mismatch & and avoidable bias problem**\n",
    "\n",
    "#### Principle:\n",
    "\n",
    "- Human level  \n",
    " $\\updownarrow$ _Avoidable bias_\n",
    "- Train set error  \n",
    " $\\updownarrow$  _variance_\n",
    "- Train-dev set error  \n",
    " $\\updownarrow$  _Data mismatch_  \n",
    "- Dev set error  \n",
    " $\\updownarrow$  _degree of the overfitting to the **dev set**_\n",
    "- Test set error \n",
    "\n",
    "If the egree of the overfitting to the **dev set** is large, a larger **dev set** is needed. \n",
    "\n",
    "#### General principle\n",
    "\n",
    "| | General data | specific data | label | \n",
    "| --- | --- | --- | --- |\n",
    "| human level | _human level_ | _---_ | $\\downarrow$ **avoidable bias** |\n",
    "| Error on train | _trainin error_ | _---_ | $\\downarrow$ **variance** |\n",
    "| Error in new data | _training-dev error_ | _dev/test error_ |\n",
    "| | | $\\leftarrow$ **data mismatch** |\n",
    "\n",
    "### Adressing data mismatch:  \n",
    "- Manual error analysis (understand differences between data)\n",
    "- Make train data similar to dev/test set (augment train set)\n",
    "    - _Artifitial data sythesis_ (augment data with noise/random features) **NOTE** this might lead to overfitting of this subset of data sythesised\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Using NN train on ony data type to recognize other data type. \n",
    "\n",
    "> This is sequential process\n",
    "\n",
    "Replace the last layer with the new output layer for the new data type.  \n",
    "Train (i) NN with only last layer changing weghts (for small datasets) or (ii) the entire NN changes in re-train (for large datasets)\n",
    "\n",
    "> Pre-training and fine-tuning\n",
    "\n",
    "This works because some of the low-level pictues / signals are similar and can be recognized  \n",
    "\n",
    "Multiple layers can also be added at the end of the NN. \n",
    "\n",
    "This is usefull, if you have a lot of data for one task and very little for another. But there should be similarities between datas.  \n",
    "\n",
    "#### Transfer learning is usfull is\n",
    "- Same input x between task A and task B\n",
    "- A lot more data for task A than B\n",
    "- Low-level features are expected to be the same \n",
    "\n",
    "### Multi-task learning\n",
    "\n",
    "> Simultanous learning\n",
    "\n",
    "Usefull when multiple features needs to be learned from data.  \n",
    "Example: image with many interesting objects.  \n",
    "Each new output of the NN than would stand for that specific object.  \n",
    "If one image has several feuares the **logistic regression** for output layers is used. Not softmax.  \n",
    "\n",
    "This is multitask learning as several features are being learned at the same time.  \n",
    "\n",
    "#### It makes sesne if \n",
    "- Trainin on set of tasks that could have many low-level features shared\n",
    "- The amount of data for each task is approximately equal \n",
    "- Can train a big enough NN to do well on all the tasks (e.g., computer vision)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### End-to-end Deep learining\n",
    "\n",
    "There are generally many stages in data processing between input, e.g., audio, to output, e.g., transcript.  \n",
    "\n",
    "This is achieved via Deep Learning.  \n",
    "\n",
    "This requires a lot of data\n",
    "\n",
    "Otherwise, intermediate steps are required.   \n",
    "\n",
    "In some cases, there is still a need for intermeedate step, where an exact part of data, e.g., face of a person, is extracted and then a NN compares this face with other faces in its training set. \n",
    "\n",
    "> If there is not enough data to solve entire problem, but there is enough to solve it by parts -- several deep-learning projects can be done \n",
    "\n",
    "Example 2. machine trainslation. \n",
    "\n",
    "Example 3. x-ray image extraction age of the person (image -> bons -> length -> child/non-child)\n",
    "\n",
    "\n",
    "Benifits of End-to-End\n",
    "- Let data speak (avoiding human biase e.g., phones of the workds)\n",
    "- Less hand-designing needed\n",
    "\n",
    "Negatives:\n",
    "- May need very large amount of data\n",
    "- Excludes potentially usefull hand-made components \n",
    "\n",
    "For end-to-end Deep learining, a large amount of data is needed for more complex relations: random photo->person vs face image->person. One is much harder than the other.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
