{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other application of ConvNets\n",
    "\n",
    "### What is Face Recognition?\n",
    "\n",
    "Face recognition and lifeness detection\n",
    "\n",
    "Face verification vs Face recognition. \n",
    "Verification (1 to 1 problem)\n",
    "\n",
    "Recognition is much harder. \n",
    "\n",
    "### One-shot learning problem \n",
    "(Given one example, you need to recognize similar ones)\n",
    "This is needed for most verification system. \n",
    "\n",
    "Feed a new image to ConvNet and pass a soft-max with probabilities for various people.  \n",
    "\n",
    "Learn a `similarity` function. \n",
    "$d(\\text{img}_1,\\text{img}_2) \\leq\\tau$ -> predict the \"same\" else \"different\" people.  \n",
    "\n",
    "Function $d$ does pair-wise comparison for each new face/image to compare with those used in training.  \n",
    "\n",
    "### Siamese Network\n",
    "\n",
    "In this __ConvNet__ converts image to a FC layer, $f(x^{(1)})$, an __encoding__ of an image.  \n",
    "The same is done for other images, -- _encoding_ vectors are created for each image.  \n",
    "\n",
    "Run $N$ identical NNs on N different inputs and compare the results as follows\n",
    "\n",
    "Define than distance $d(x^{(1)},x^{(2)})$ as a distance between two images $|| f(x^{(1)}) - f(x^{(2)})||$.\n",
    "If same person $d(...)<\\tau$\n",
    "\n",
    "This is called _siamese network_. (See paper by ) Yaniv Taigman 2014 DeepFace.  \n",
    "\n",
    "### Triplet Loss Function\n",
    "\n",
    "Comparing pairs of images. Several pictures at the same time should be analyzed. \n",
    "\n",
    "In `triplet loss` function one compares the `anchor` with `positive (P)` image (which is the same, but different) and `negative (N)` which is differnt object/person. \n",
    "\n",
    "The following propertiy is desired:\n",
    "$$\n",
    "|| f(x^{(A)}) - f(x^{(P)})||^2 \\leq \n",
    "|| f(x^{(A)}) - f(x^{(N)})||^2\n",
    "$$\n",
    "\n",
    "i.e., comparing distances. \n",
    "\n",
    "Modification is needed to avoid zeroes in all encodings (trivial solution) \n",
    "\n",
    "$$\n",
    "d(x^{(A)},x^{(P)}) - d(x^{(A)},x^{(N)}) +\\alpha \\leq 0\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is `margine`. \n",
    "\n",
    "The `triplet loss function` is defined for three images as: \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\max\\Big( \n",
    "    || f(x^{(A)}) - f(x^{(P)})||^2 - \n",
    "    || f(x^{(A)}) - f(x^{(N)})||^2 + \\alpha, 0\\Big)\n",
    "$$\n",
    "\n",
    "So, the expression can be as negative as possible, but less then 0.\n",
    "\n",
    "$$\n",
    "j = \\sum\\mathcal{L}(A^{(i)},P^{(i)},N^{(i)})\n",
    "$$\n",
    "\n",
    "Note, pairs of pictures are needed. Large number of pairs of pictures. After training, one picture should be enough. \n",
    "\n",
    "**Note** In paris of images are chose randomly, than the constraint $d(A,P) + \\alpha \\leq d(A,N)$ is easy to satisdy. \n",
    "\n",
    "**Triplets have to be chosen so that they are hard to classify**\n",
    "\n",
    "Tis increases the computational efficiently of the training.  \n",
    "\n",
    "Schroff et al 2015 FaceNet paper. \n",
    "\n",
    "All of this is made to learn an encoding. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face verification and binary classification\n",
    "\n",
    "Another way to do face regnition.  \n",
    "\n",
    "This is done by combining these different nets and outputing a signle softmax output $\\hat{y}$, computing the __difference between encodings__. \n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma\\Big( \\sum_{k=1}^{128} | f(x^{(i)})_k - f(x^{(j)})_j | + b \\Big)\n",
    "$$\n",
    "\n",
    "feeding this into _logistic regresion_ wit a stanrard unit and outputing the probability of a similarity.  \n",
    "\n",
    "Sometimes $\\chi^2$ similarity is also employed. \n",
    "\n",
    "Note, that _precomputing_ embeding can save computational cost. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Style Transfer \n",
    "\n",
    "Convert a style of one omage into a style of a different image. \n",
    "Consider $C$ as a content image, $S$ as a style image and $G$ as a generated image.  \n",
    "\n",
    "THis is done by considering features learned at various layers of a _ConvNet_. \n",
    "\n",
    "### What are deep ConvNets learning?\n",
    "\n",
    "Consider a ConvNet and exampine its layers.  \n",
    "Take all the training examples, pass through the Net and fine __what image maximises the activation values in this layer__. Plot the image patches that the layer leared.\n",
    "Usually, these are basic shapes, like lines. \n",
    "\n",
    "Repeat the procedure for other hidden units. \n",
    "This is called `receptive field`. \n",
    "\n",
    "Hidden units in lyaer one are learning simple features. \n",
    "\n",
    "See Paper by Zieler et al 2013 Visualazing and understanding ConvNets\n",
    "\n",
    "Now consider _deeper layers_ where NN sees __Larger__ part of the image, and they are learning features seen with a larger _receprive field_.  \n",
    "\n",
    "Each layer is detecting more sophysitcated shapes and categories of objects. \n",
    "\n",
    "### Cost function for neural Style transfer\n",
    "\n",
    "First. Define $J(G)$. \n",
    "1. Contect part \n",
    "2. Style part\n",
    "\n",
    "$$\n",
    "J = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)\n",
    "$$\n",
    "\n",
    "Paper suggested Gatys et al 2015 A neural algorithm of artistic style \n",
    "\n",
    "- Init the G randomly (white noise image)\n",
    "- Define and minimize $J(G)$ and update the $G:=G-\\frac{\\partial}{\\partial G}J(G)$\n",
    "\n",
    "This will slowly turn the noise-image into the image with the content and style. \n",
    "\n",
    "### Content Cost Function\n",
    "\n",
    "Consider layer $l$, there $a^{[l][C]}$ and $a^{[l][G]}$ activations hwen content and generated image are passed and the cost fanction there then is \n",
    "$$\n",
    "J_{\\rm content}(C,G) = \\frac{1}{2} || a^{[l][C]} - a^{[l][G]} ||\n",
    "$$\n",
    "Not that for this a _pre-trained NN_ (like __VGG__) was used.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style Cost Function\n",
    "\n",
    "Consider a ConvNet with input in three color channels and a set of lyaers, converting the width and height of the image to the depth.\n",
    "\n",
    "Define a style as a `correlation between activations across different channels`. \n",
    "\n",
    "Channels are related to colors. \n",
    "Examining two chanels, one can look at the pairs for a given position $H$ and $W, and how correlated are these numbers across the enitre image. \n",
    "\n",
    "See paper by Garys et al 2015 A neural algorithm of artistic style \n",
    "\n",
    "Correlation says which of the high level components do or do not occure together. \n",
    "Degree of correlation gives how often these features do occure (texture, colors, etc). \n",
    "\n",
    "Given an image, compute the _style matrix_ as $a_{ijk}^{[l]} = $activation at $(i,j,k)$ $G^{[l]}$ is $n_c^{[l]}\\times n_c^{[l]}$\n",
    "\n",
    "One element is computed as __unnormalized cross-covaraince__ grand matrixes:\n",
    "\n",
    "$$\n",
    "G_{kk'}^{[l][S]} = \\sum_{i=1}^{n_{\\rm H}}\\sum_{j=1}^{n_{\\rm W}} a_{ijk}^{[l][S]} a_{ijk'}^{[l][S]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "G_{kk'}^{[l][G]} = \\sum_{i=1}^{n_{\\rm H}}\\sum_{j=1}^{n_{\\rm W}} a_{ijk}^{[l][G]} a_{ijk'}^{[l][G]}\n",
    "$$\n",
    "\n",
    "These two matrixes capture the styles of image S and G.  \n",
    "\n",
    "And the style cost function reads \n",
    "\n",
    "$$\n",
    "J_{\\rm style}^{[l]}(S,G) = \\frac{1}{(2 n_{\\rm H}^{[l]} n_{\\rm W}^{[l]} n_{\\rm C}^{[l]})^2} \\sum_k \\sum_{k'} \\big(  G_{kk'}^{[l][S]} - G_{kk'}^{[l][G]}\\big)^2\n",
    "$$\n",
    "\n",
    "The overall cost function than is a weighted sum \n",
    "\n",
    "$$\n",
    "J_{\\rm style}(S,G) = \\sum_l \\lambda^{[l]} J_{\\r style}^{[l]}(S,G)\n",
    "$$\n",
    "\n",
    "with a hyererparameter controls how much various layers learn.  \n",
    "\n",
    "The overall cost function now is \n",
    "$$\n",
    "J(G) = \\alpha J_{\\rm cost}(C,G) + \\beta J_{\\rm style}(S,G)\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions in 1D and 3D generalization\n",
    "\n",
    "ConvNets acan be used for 1D or 3D data as well.  \n",
    "\n",
    "For a signal, for example, EGG diagram, one can use a 1D ConvNet (_time series_ analysis) wih 1D filter. Simialar, the signal time resolutio shrinks each time the convolution is done.   \n",
    "\n",
    "Mostly, hpwever, __recurrent NNs__ are used.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
