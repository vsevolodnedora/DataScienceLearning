{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Localization\n",
    "\n",
    "### Object localization\n",
    "\n",
    "- Classification with localization problem\n",
    "- Detection problem (for multiple objects)\n",
    "\n",
    "In **Image Classification**, the image is passed through *ConvNet* and *softmax* to extract the class.  \n",
    "\n",
    "For localization, we need to change the NN to get the bounding box. $b_x$, $b_y$, $b_h$, $b_w$. \n",
    "\n",
    "If training set contains the bounding box data, the bounding box can be learned and found in new data. \n",
    "\n",
    "How to define the target label $y$?  \n",
    "Assume that $y$ is a vector $[p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3]^T$,  where $p_c$ probability that the object is there. And $c_i$ are probabilities for different classes of the object (1 or 0).  \n",
    "\n",
    "Loss function $\\mathcal{L}(\\hat{y},y)$ is sum of squared residuals for if $y_1 = 1$ (if there is an image). Otherwise we do not care about other labels, so we get \n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\hat{y},y) = \n",
    "\\begin{cases}\n",
    "\\sum(\\hat{y}_i - y_i)^2 \\text{ if } y_1 = 1 \\\\\n",
    "(\\hat{y}_1-y_1)^2 \\text{ if } y_1 = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Landmark detection \n",
    "\n",
    "Outpot an important points of the image (coordinates)\n",
    "\n",
    "An image can have many landmarks of interest (facial features). These can be extracted via *ConvNet*. This is used to extract emoptions, etc.  \n",
    "Computer graphics.  \n",
    "\n",
    "The labels in the train set are usually prepared _manually_. \n",
    "\n",
    "Labells have to be consistent between different images.  \n",
    "\n",
    "### Object detection\n",
    "\n",
    "Using _sliding window_ dectection algorithm and _ConvNet_.  \n",
    "- Create training set with __closely cropped__ image of an object (e.g., car)\n",
    "- and images without a car.  \n",
    "- Create a ConvNet to classifiy these crops if it is a car or not.  \n",
    "- Create a slide-window detection. For atest image, pick the window size and scroll through the entire image with the \"window\" (with a small stride). Classify each part of the image whether it is a car not. \n",
    "    - Resize the window and repeat the process\n",
    "    - Resize again and repeat \n",
    "\n",
    "> So, if there is a car in the image, the ConvNet should give positive at least once in this search. \n",
    "\n",
    "**Distadvantage** Very computatiaonlly expensive\n",
    "\n",
    "**Solution** Convolutional implementation of a sliding-window\n",
    "\n",
    "### Convolutional Implementation of Sliding Windows\n",
    "\n",
    "Turning FC layers into ConvLayers.  \n",
    "\n",
    "Consider an image $(14\\times14\\times3)$ then $5\\times5$ layers to make $(10\\times10\\times16)$ and then $2\\times2$ MAXPOOL to make $(5\\times 5\\times 16)$ ... then FC, FC, softmax with say $4$ labels for 4 varius objects present in the image.  \n",
    "\n",
    "In order to convert the last FC layers to ConvLayers, we repalce $1$ FC laer with $400$ neurons with $400$ ConvLayers with $5\\times 5$ so that ouput is $1\\times1\\times400$, then you need another $400$ of $1\\times 1$ filters. \n",
    "\n",
    "Implementation is from OverFeat paper: by Sermanet et al 2014. \n",
    "\n",
    "Consider imput of $(14\\times14\\times3)$ image. \n",
    "\n",
    "$$\n",
    "\\Big[ 14\\times14\\times3 \\Big]\n",
    "\\underbrace{\\rightarrow}_{5\\times 5}\n",
    "\\Big[ 10\\times 10\\times 16 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{2\\times 2}}^{\\text{MAX POOL}}\n",
    "\\Big[ 5\\times 5\\times 16 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{5\\times 5}}^{\\text{FC}}\n",
    "\\Big[ 1\\times 1\\times 400 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{1\\times 1}}^{\\text{FC}}\n",
    "\\Big[ 1\\times 1\\times 400 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{1\\times 1}}^{\\text{FC}}\n",
    "\\Big[ 1\\times 1\\times 4 \\Big]\n",
    "$$\n",
    "\n",
    "Consider a larger input image: \n",
    "\n",
    "$$\n",
    "\\Big[ 16\\times 16\\times 3 \\Big]\n",
    "\\underbrace{\\rightarrow}_{5\\times 5}\n",
    "\\Big[ 12\\times 12\\times 16 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{2\\times 2}}^{\\text{MAX POOL}}\n",
    "\\Big[ 6\\times 6\\times 16 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{5\\times 5}}^{\\text{FC}}\n",
    "\\Big[ 2\\times 2\\times 400 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{1\\times 1}}^{\\text{FC}}\n",
    "\\Big[ 2\\times 2\\times 400 \\Big]\n",
    "\\overbrace{\\underbrace{\\rightarrow}_{1\\times 1}}^{\\text{FC}}\n",
    "\\Big[ 2\\times 2\\times 4 \\Big]\n",
    "$$\n",
    "\n",
    "The resulting $4$ in the output volume represents the results if we took the original image and movied it within the bigger 16 by 16 image, rerunning the net each time. But, but doing it like this we duplicate a lot of calcualtions!\n",
    "In the above implementaion, many calculations are shared. \n",
    "The `MAX POOL` layer guverns the stride with which we \"slide the window\" and the output density.  \n",
    "\n",
    "> Convolutional implementation allows to process the entire image without manually sliding the window and _rerunning_ the net every time!\n",
    "\n",
    "**Shortcoming** position of the bounding boxes is not accurate \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Box Predictions\n",
    "\n",
    "It is possible that non of the boxes matches the position of the car.  \n",
    "\n",
    "Especially if bounding box may not be perfectly squred. \n",
    "\n",
    "Solution: `YOLO` algorithm (you only look once). See Redmon et al 2015 paper. \n",
    "\n",
    "Idea: Devide a given image into _cells_. And process each cell of the grid spearately through the ConvNet discussed above. For each grid cell there exists a label $y=[p_c,b_x, b_y, b_h, b_w, c_1, c_2, c_3]^T$.  \n",
    "Assign object to the center of a given cell, if the __object center__ lies within the boundaries of this grid cell.  \n",
    "\n",
    "__Target output volume__ is $3\\times 3\\times 8$  for $8$ labels in the $Y$ and $3\\times 3$ cell devision. \n",
    "\n",
    "On the other side, Use the __ConvNet__ to process the image and adjust the layers such, that the output shape is equal to the shape of the _target volume_. \n",
    "\n",
    "use backprop to train the NN to output the target volume.  \n",
    "\n",
    "Advantage: faster.  \n",
    "**Note** there should be one object of interest in a gird cell.  \n",
    "**Single Conv. implementation**  \n",
    "\n",
    "#### Specifying the boundary boxes\n",
    "\n",
    "In YOLO algorithm in each cell, the opposite corners have (1,1) and $(0,0)$. Then, the coordinates are specified within these bounds. $x_{i}\\int(0,1)$ however width and hight can be larger than $1$.  \n",
    "\n",
    "### Intesection Over Union\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
