{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative loop of ML development\n",
    "\n",
    "1. Chose architecture (model, data, etc)\n",
    "2. Train the model\n",
    "3. Diagnostics (vias, variance, error analysis)\n",
    "4. Change the NN, adjust hyperparmeters\n",
    "5. Repeat\n",
    "\n",
    "Consider email classifier problem:  \n",
    "One way is to train a supervised NN. $X=$[features of email] $Y=$[1 or 0] (spam or not spam).  \n",
    "To do that use language $10^4$ words and use one-hot-encoding for each word to be present. And creaste a feature vector for an email. There are many ways to construct a feature vector. Not with one-hot-encoding but count the number of these words present. \n",
    "\n",
    "Improving: collect more data. \n",
    "\n",
    "How to chose which approach is better:\n",
    "# Error analysis\n",
    "\n",
    "- Manually examining set of misclassified examples:  \n",
    "Consider $m_{cv}$ and $100$ are misclassified. Try to group them by a common aspect. Find which is the largest group. Try to address the algorithm to catch this group better.\n",
    "\n",
    "# Adding data\n",
    "\n",
    "- Focus on the data where the error analysis indicated, it is required. \n",
    "\n",
    "- Data augmentation: using existing data, modify it to create a new training example (using distortion, transformation, resizing, grid warping, etc) or (for audio: noise, combination of audio plus background, filtering,  masking...) \n",
    "\n",
    "- Data synthesis (creating new training data from scratch) Allows to generate large amount of data. Used in compute vision.\n",
    "\n",
    "Conventional model-centric approach (focus on model development, fixing data) \n",
    "\n",
    "Data-centric approach: focus on data more than on the algorithm\n",
    "\n",
    "# Transfer learning (for small datasets)\n",
    "\n",
    "Use datasets from other applications. \n",
    "Consider a NN trained on a large dataset for one problem, e.g., cat/dog recognition. \n",
    "\n",
    "Then copy the NN and use parameters $\\vec{w}_i^{[j]},b_{i}^{[j]}$ for all its layers as an **initial point** for a new NN with a new **output layer** for the new problem, i.e., digit recognition.  \n",
    "In otherwords. Do **supervised pre-training** of the NN on one prolem, and finilize or **fine-tune** the training on a problem (with new output layer) you need with smaller dataset.  \n",
    "- There you can only train the last layer (for very small set). \n",
    "- Or you can train all the NN parameters (for a bit larger set)\n",
    "\n",
    "Often the pre-train models are already exist.  \n",
    "**Note** the size of the input should the the same though.\n",
    "\n",
    "# Full cycle of ML project\n",
    "\n",
    "1. Scope of the project (Define a project) Goal. \n",
    "2. Collect data. Decite what data, labels, etc\n",
    "3. Train the model, error anlysis, iteratively imporve the model. \n",
    "4. Deploy in a production environment (maintain)\n",
    "\n",
    "**Deployment**: Implement a ML model in a _inference server_. For a front-end create a mobile app, tha makes and _API call_ to the inference server by sending the 'test data' and the server would retern an inference (prediction). Software engineering is required for \n",
    "- Reliable and efficient predictions \n",
    "- Scaling \n",
    "- Logging \n",
    "- System monitoring \n",
    "- Model ipdates\n",
    "Consdier `MLops` for machine learning operations\n",
    "\n",
    "There is no checklist to be ethitcal...)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
